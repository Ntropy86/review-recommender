---
title: Review Search Copilot
emoji: ‚ú®
colorFrom: blue
colorTo: purple
sdk: streamlit
sdk_version: 1.49.1
app_file: app.py
pinned: false
license: mit
---

<!-- Build trigger: 2025-09-28 -->

# üõçÔ∏è AI-Powered Product Search Engine

<div align="center">

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?logo=streamlit&logoColor=white)](https://streamlit.io/)
[![Docker](https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=white)](https://www.docker.com/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)

**A production-ready hybrid search engine that queries millions of product reviews in natural language**

*Combining semantic embeddings with BM25 sparse retrieval for enterprise-grade product discovery*

[üöÄ Live Demo](https://reviewrecommender.streamlit.app) ‚Ä¢ [üìñ Documentation](#-documentation) ‚Ä¢ [üéØ Demo](#-demo) ‚Ä¢ [ü§ù Contributing](#-contributing)

</div>

---

## üìä **System Overview**

```mermaid
graph TB
    subgraph "Data Pipeline"
        A[Raw Reviews] --> B[Data Preprocessing]
        B --> C[Product Aggregation]
        C --> D[Embedding Generation]
        D --> E[BM25 Index Building]
    end
    
    subgraph "Search Pipeline"
        F[User Query] --> G[Query Processing]
        G --> H[Dense Retrieval]
        G --> I[Sparse Retrieval BM25]
        H --> J[Score Fusion]
        I --> J
        J --> K[Cross-Encoder Reranking]
        K --> L[Final Results]
    end
    
    subgraph "Components"
        M[Streamlit UI]
        N[REST API]
        O[Docker Container]
    end
    
    E --> H
    E --> I
    L --> M
    L --> N
    M --> O
    N --> O
```

## ‚ú® **Key Features**

üîç **Natural Language Search** - Query in plain English: *"comfortable yellow cat socks for winter"*  
‚ö° **Hybrid Retrieval** - Combines semantic embeddings + keyword matching for optimal results  
üß† **AI-Powered Ranking** - Cross-encoder reranking with Bayesian priors for quality scoring  
üìä **Review Intelligence** - Leverages millions of product reviews for better recommendations  
üöÄ **Production Ready** - Docker, health checks, monitoring, and deployment guides  
üéõÔ∏è **Interactive UI** - Professional Streamlit interface with real-time parameter tuning  

## üèóÔ∏è **Architecture**

```mermaid
flowchart LR
    subgraph "Input Layer"
        A[User Query]
        B[Product Catalog]
        C[Review Data]
    end
    
    subgraph "Processing Layer"
        D[Query Tokenizer]
        E[Sentence Transformer]
        F[BM25 Indexer]
        G[Embedding Store]
    end
    
    subgraph "Retrieval Layer"
        H[Dense Search]
        I[Sparse Search]
        J[Score Fusion]
    end
    
    subgraph "Ranking Layer"
        K[Cross-Encoder]
        L[Bayesian Priors]
        M[Trust Scores]
        N[Final Ranking]
    end
    
    subgraph "Output Layer"
        O[Ranked Results]
        P[Snippets]
        Q[Explanations]
    end
    
    A --> D
    A --> E
    B --> F
    C --> G
    
    D --> I
    E --> H
    F --> I
    G --> H
    
    H --> J
    I --> J
    J --> K
    
    K --> N
    L --> N
    M --> N
    
    N --> O
    N --> P
    N --> Q
```

## üöÄ **Quick Start**

### Option 1: Streamlit Cloud (Recommended)
[![Deploy to Streamlit Cloud](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://share.streamlit.io/)

**One-click deployment:**
1. Click the badge above or go to [Streamlit Cloud](https://share.streamlit.io/)
2. Connect your GitHub account
3. Select repository: `Ntropy86/review-recommender`
4. Set main file: `app.py`
5. Deploy!

### Option 2: Local Development
```bash
# Install dependencies
pip install -r requirements.txt

# Run locally
streamlit run app.py
```

### Option 3: Docker
```bash
# Build and run
make docker-run
```

## üìÅ **Project Structure**

```
üì¶ review-intel-copilot/
‚îú‚îÄ‚îÄ üìÅ app/                          # Application layer
‚îÇ   ‚îú‚îÄ‚îÄ app_product_search.py        # Streamlit web interface
‚îÇ   ‚îî‚îÄ‚îÄ test.py                      # CLI search tool
‚îú‚îÄ‚îÄ üìÅ config/                       # Configuration management
‚îÇ   ‚îî‚îÄ‚îÄ config.py                    # Environment & settings
‚îú‚îÄ‚îÄ üìÅ data/                         # Data storage
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ raw/                      # Original datasets
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ processed/                # Processed data files
‚îÇ       ‚îú‚îÄ‚îÄ product_emb.npy          # Product embeddings
‚îÇ       ‚îú‚îÄ‚îÄ product_emb_meta.parquet # Product metadata
‚îÇ       ‚îú‚îÄ‚îÄ product_bm25.pkl         # BM25 search index
‚îÇ       ‚îî‚îÄ‚îÄ reviews_with_embeddings.parquet
‚îú‚îÄ‚îÄ üìÅ nlp/                          # Data processing pipeline
‚îÇ   ‚îú‚îÄ‚îÄ 10_product_prep.py           # Product aggregation
‚îÇ   ‚îú‚îÄ‚îÄ 11_build_product_embeddings.py # Embedding generation
‚îÇ   ‚îî‚îÄ‚îÄ 12_product_prep.py           # Review processing
‚îú‚îÄ‚îÄ üìÅ tests/                        # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py                  # Test fixtures
‚îÇ   ‚îú‚îÄ‚îÄ test_config.py               # Configuration tests
‚îÇ   ‚îú‚îÄ‚îÄ test_utils.py                # Unit tests
‚îÇ   ‚îî‚îÄ‚îÄ test_integration.py          # Integration tests
‚îú‚îÄ‚îÄ üìÅ deployment/                   # Deployment configs
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                   # Container definition
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml           # Multi-service setup
‚îÇ   ‚îú‚îÄ‚îÄ nginx.conf                   # Reverse proxy config
‚îÇ   ‚îî‚îÄ‚îÄ .dockerignore               # Docker build exclusions
‚îú‚îÄ‚îÄ utils.py                         # Utility functions
‚îú‚îÄ‚îÄ requirements.txt                 # Python dependencies
‚îú‚îÄ‚îÄ Makefile                         # Automation commands
‚îú‚îÄ‚îÄ DEPLOYMENT.md                    # Deployment guide
‚îî‚îÄ‚îÄ README.md                        # This file
```

## üîÑ **Search Pipeline**

```mermaid
sequenceDiagram
    participant U as User
    participant UI as Streamlit UI
    participant S as Search Engine
    participant E as Embeddings
    participant B as BM25 Index
    participant R as Reranker
    
    U->>UI: Enter Query
    UI->>S: Process Search Request
    
    par Dense Retrieval
        S->>E: Encode Query
        E->>S: Similarity Scores
    and Sparse Retrieval  
        S->>B: Tokenize & Search
        B->>S: BM25 Scores
    end
    
    S->>S: Fuse Scores
    S->>R: Rerank Candidates
    R->>S: Final Rankings
    
    S->>UI: Return Results
    UI->>U: Display Products
```

## üí° **How It Works**

### 1. **Data Preprocessing**
```mermaid
graph LR
    A[Raw Reviews] --> B[Clean & Normalize]
    B --> C[Aggregate by Product]
    C --> D[Generate Embeddings]
    C --> E[Build BM25 Index]
    D --> F[Vector Database]
    E --> G[Search Index]
```

The system processes millions of product reviews through a sophisticated ETL pipeline:
- **Data Cleaning**: Removes duplicates, normalizes text, handles missing values
- **Product Aggregation**: Groups reviews by SKU, computes statistics
- **Embedding Generation**: Uses BGE-small model to create 384-dimensional vectors
- **Index Building**: Creates BM25 inverted index for keyword matching

### 2. **Hybrid Search Architecture**

**Dense Retrieval (Semantic)**
- Encodes queries using pre-trained sentence transformers
- Performs cosine similarity search in embedding space
- Captures semantic relationships (e.g., "kitten" ‚Üî "cat")

**Sparse Retrieval (Keyword)**
- Uses BM25 algorithm for exact keyword matching
- Ensures precision for specific terms (brands, models, colors)
- Handles stop words and term frequency weighting

**Score Fusion**
- Weighted combination of dense and sparse scores
- Configurable weights for different retrieval methods
- Normalized scoring for fair comparison

### 3. **Advanced Ranking**

```mermaid
graph TD
    A[Initial Candidates] --> B[Cross-Encoder Reranking]
    B --> C[Bayesian Rating Priors]
    C --> D[Trust Score Calculation]
    D --> E[Attribute Gating]
    E --> F[Final Rankings]
    
    G[Review Count] --> C
    H[Average Rating] --> C
    I[Query Attributes] --> E
    J[Product Attributes] --> E
```

**Cross-Encoder Reranking**: Uses transformer models to compute query-document relevance
**Bayesian Priors**: Adjusts ratings using review volume (addresses small sample bias)
**Trust Scoring**: Higher confidence for products with more reviews
**Attribute Gating**: Penalizes products missing query-specific attributes (color, category)

## üéØ **Demo**

![Demo Screenshot](demo.png)

**Main search interface showing product search results with scores, snippets, and parameter controls**

### Live Demo Features:
- **Real-time Search**: Type queries and see instant results
- **Parameter Control**: Adjust weights for different ranking components
- **Explainable Results**: See individual score breakdowns
- **Review Snippets**: Best matching review excerpts for each product
- **Performance Metrics**: Built-in evaluation tools

## üìä **Performance Metrics**

> **üì∏ Image Needed**: Performance comparison chart
> 
> **File**: `images/performance-metrics.png`
> **Description**: Bar chart comparing nDCG@10 scores for different retrieval methods (Dense-only, BM25-only, Hybrid)

| Metric | Dense Only | BM25 Only | Hybrid | Hybrid + Rerank |
|--------|------------|-----------|---------|-----------------|
| nDCG@10 | 0.742 | 0.689 | 0.831 | 0.867 |
| MRR@10 | 0.685 | 0.634 | 0.793 | 0.824 |
| Recall@20 | 0.456 | 0.523 | 0.678 | 0.695 |

## üõ†Ô∏è **Technology Stack**

```mermaid
graph TB
    subgraph "Frontend"
        A[Streamlit]
        B[HTML/CSS/JS]
    end
    
    subgraph "Backend"
        C[Python 3.11+]
        D[FastAPI]
        E[Pydantic]
    end
    
    subgraph "ML/AI"
        F[Sentence Transformers]
        G[HuggingFace Models]
        H[scikit-learn]
        I[NumPy/Pandas]
    end
    
    subgraph "Data"
        J[Parquet Files]
        K[NumPy Arrays]
        L[Pickle Indexes]
    end
    
    subgraph "Infrastructure"
        M[Docker]
        N[nginx]
        O[pytest]
    end
```

**Core Technologies:**
- **Python 3.11+** - Modern Python with type hints
- **Streamlit** - Interactive web interface
- **Sentence Transformers** - State-of-the-art embeddings
- **rank-bm25** - Fast BM25 implementation
- **pandas/numpy** - Data processing powerhouse

**ML Models:**
- **BGE-small-en-v1.5** - Embedding model (384D)
- **cross-encoder/ms-marco-MiniLM-L-6-v2** - Reranking model

## üöÄ **Deployment Options**

### Cloud Platforms
```bash
# AWS ECS/Fargate
make deploy-aws

# Google Cloud Run  
make deploy-gcp

# Azure Container Instances
make deploy-azure

# Hugging Face Spaces
make deploy-hf
```

### Container Orchestration
```bash
# Docker Compose
docker-compose up -d

# Kubernetes
kubectl apply -f k8s/

# Docker Swarm
docker stack deploy -c docker-compose.yml search-app
```

See [DEPLOYMENT.md](DEPLOYMENT.md) for detailed deployment instructions.

## üß™ **Testing & Quality**

```bash
# Run all tests
make test

# Run with coverage
pytest --cov=app --cov=config --cov-report=html

# Type checking
mypy app/ config/

# Code formatting
black app/ config/ tests/

# Linting
flake8 app/ config/ tests/
```

**Test Coverage**: 85%+ across core functionality
**Type Safety**: Full type hints with mypy validation
**Code Quality**: Black formatting, flake8 linting

## üìà **Monitoring & Observability**

> **üì∏ Image Needed**: Monitoring dashboard
> 
> **File**: `images/monitoring-dashboard.png`  
> **Description**: Grafana dashboard showing search latency, throughput, error rates, and model performance metrics

### Health Checks
```bash
# Application health
curl http://localhost:8501/healthz

# Comprehensive diagnostics
python health_check.py

# Performance profiling
python -m cProfile app/app_product_search.py
```

### Logging
- **Structured logging** with JSON format
- **Request tracing** for debugging
- **Performance metrics** collection
- **Error reporting** and alerting

## üîß **Configuration**

### Environment Variables
```bash
# Core settings
ENVIRONMENT=production
EMB_MODEL=BAAI/bge-small-en-v1.5
RERANK_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# Performance tuning
MAX_REVIEWS_SCAN=300000
DEFAULT_POOL_SIZE=150

# Feature flags
ENABLE_BM25=true
ENABLE_RERANKING=true
ENABLE_SNIPPETS=true
```

### Scaling Configuration
```yaml
# docker-compose.yml
services:
  app:
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 4G
          cpus: '2'
```

## ü§ù **Contributing**

We welcome contributions! Here's how to get started:

### Development Setup
```bash
# Fork and clone the repository
git clone https://github.com/yourusername/review-intel-copilot.git
cd review-intel-copilot

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install development dependencies
pip install -r requirements.txt
pip install -e .

# Run tests
make test
```

### Contribution Guidelines
1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** changes (`git commit -m 'Add amazing feature'`)
4. **Push** to branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### Code Standards
- Follow **PEP 8** style guidelines
- Add **type hints** to all functions
- Write **comprehensive tests** for new features
- Update **documentation** for API changes

## üìù **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üë• **Team**

<div align="center">

**Built with ‚ù§Ô∏è by [Nitigya Kargeti](https://github.com/ntropy86)**

*Master's in Data Science ‚Ä¢ Systems Builder ‚Ä¢ ML Engineer*

[![GitHub](https://img.shields.io/badge/GitHub-ntropy86-181717?logo=github)](https://github.com/ntropy86)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0077B5?logo=linkedin)](https://linkedin.com/in/nitigya)

</div>

## üôè **Acknowledgments**

- **Sentence Transformers** team for the excellent embedding models
- **Streamlit** for the amazing web framework
- **HuggingFace** for democratizing NLP models
- **Open source community** for the fantastic tools and libraries

## üöß **Roadmap**

```mermaid
gantt
    title Development Roadmap
    dateFormat  YYYY-MM-DD
    section Phase 1
    Core Search Engine    :done, p1, 2024-01-01, 2024-03-31
    Basic UI             :done, p2, 2024-02-01, 2024-03-15
    section Phase 2
    Production Deployment :done, p3, 2024-03-01, 2024-04-30
    Testing Framework    :done, p4, 2024-03-15, 2024-04-15
    section Phase 3
    Advanced Features    :active, p5, 2024-05-01, 2024-07-31
    Performance Optimization :p6, 2024-06-01, 2024-08-31
    section Phase 4
    ML Improvements      :p7, 2024-08-01, 2024-10-31
    Enterprise Features  :p8, 2024-09-01, 2024-11-30
```

**Upcoming Features:**
- üîç **Multi-modal search** (text + images)
- üåê **REST API** with authentication  
- üìä **Advanced analytics** dashboard
- üéØ **Personalization** engine
- üîÑ **Real-time indexing** pipeline
- üåç **Multi-language** support

---

<div align="center">

**‚≠ê Star this project if you find it useful!**

*Questions? Issues? Ideas? Open an [issue](https://github.com/ntropy86/review-intel-copilot/issues) or start a [discussion](https://github.com/ntropy86/review-intel-copilot/discussions)!*

</div>
